{"meta":{"title":"KLEON","subtitle":null,"description":"Think About The Big Map","author":"Kleon","url":"http://blog.kleon.space"},"pages":[{"title":"分类","date":"2018-12-12T14:35:52.074Z","updated":"2018-12-12T14:35:52.074Z","comments":true,"path":"categories/index.html","permalink":"http://blog.kleon.space/categories/index.html","excerpt":"","text":"XX分类，从我做起。"},{"title":"","date":"2018-12-12T14:35:20.745Z","updated":"2018-12-12T14:35:20.745Z","comments":true,"path":"about/index.html","permalink":"http://blog.kleon.space/about/index.html","excerpt":"","text":"没啥说的，上班不如上学好。"},{"title":"标签","date":"2018-11-20T14:14:04.418Z","updated":"2018-11-20T14:14:04.418Z","comments":true,"path":"tags/index.html","permalink":"http://blog.kleon.space/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-13T14:53:35.843Z","updated":"2018-12-13T14:53:35.843Z","comments":true,"path":"googlebe23cb0bc55fc412.html","permalink":"http://blog.kleon.space/googlebe23cb0bc55fc412.html","excerpt":"","text":"google-site-verification: googlebe23cb0bc55fc412.html"}],"posts":[{"title":"人工智能路线图","slug":"ai/report2018","date":"2018-12-10T11:00:00.000Z","updated":"2018-12-13T14:39:49.747Z","comments":true,"path":"2018/12/ai/report2018/","link":"","permalink":"http://blog.kleon.space/2018/12/ai/report2018/","excerpt":"本文将从多个角度分别展示人工智能的发展现状。深度学习的核心是算法模型，更高的质量，更快的速度都离不开模型的创新与调参。同时训练与执行需要一套高效的系统，主要包括前端框架与后端设备。前端框架搭建与优化模型，后端设备实际运行计算。深度学习系统的开源化使得模型的训练与部署都相当容易，因此基于深度学习的应用也层出不穷，商业与技术结合碰撞出火花和泡沫。","text":"本文将从多个角度分别展示人工智能的发展现状。深度学习的核心是算法模型，更高的质量，更快的速度都离不开模型的创新与调参。同时训练与执行需要一套高效的系统，主要包括前端框架与后端设备。前端框架搭建与优化模型，后端设备实际运行计算。深度学习系统的开源化使得模型的训练与部署都相当容易，因此基于深度学习的应用也层出不穷，商业与技术结合碰撞出火花和泡沫。 模型 对于深度学习算法来说，神经网络的模型是最为关键的。模型的种类与规模成千上万，但都基于三种基本的网络层结构：DNN、CNN、RNN。在这三种网络层结构之上又引入了多层结构，如Resnet，Inception等，用于避免梯度消失和降低计算量等。在基本的网络结构之上，构建了面向不同应用领域的模型，如GAN，RL，GNN等。 系统 深度学习系统正在不断发展与完善之中。利用深度学习框架，就可以可以搭建神经网络，并在CPU与GPU上执行。 主流的计算框架包括： Google家的Tensorflow，背靠TPU Facebook家的PyTorch UCB家的Caffe 这些框架的主要目标平台是GPU，但GPU功耗较高，端到端延迟较大，几乎统治了训练领域。在预测领域，专用芯片可以获得比GPU更高的效率，并且可以根据场景的性能要求与功耗限制定制芯片。 因此适配不同框架到不同的后端设备成了必要的需求。微软、脸书、亚马逊共同推出的ONNX（Open Neural Network Exchange）试图通过统一的Runtime沟通不同的前端框架；NNVM携带自己的TVM试图搭建前端到设备端的编译路径；而Tensorflow自成一体，使用XLA统一中间表示，并适配不同后端设备的优化pass。 框架 深度学习训练与部署的框架百花齐放，以Tensorflow为首，PyTorch，Caffe等紧随其后。各家平台构建网络时特点不同，并不同程度地支持分布式训练。由于社区的开源工作，单机搭建深度学习平台已经相当容易，然而受限于计算资源，难以训练较大规模的模型。对深度学习的训练与部署平台的需求也与日俱增。 除此之外，框架对于底层计算平台的可拓展能力也被看重，Tensorflow的XLA，NNVM的TVM都利用统一的IR与优化pass适配不同的底层硬件。 设备 深度学习模型训练（Training）与预测（Inference）在CPU上表现欠佳，因而发展出了多种类型的异构计算系统用于加速模型的训练与预测。以GPU为首，NVIDIA推出cuDNN库，作为各种框架的底层平台，已经得到了大规模的应用。除此之外，各类专用芯片也迅速进入异构计算系统中。以FPGA为平台，可以较快适应模型的算法创新，虽然可以获得较高的加速比，但计算效率并不高。ASIC芯片中，以Google的TPU最为出名，同时支持训练与预测。 应用 深度学习目前在图像识别领域最为成熟，各类模型与系统最为丰富。基于图像识别领域的目标检测，语义分割等，支撑了工业检测、安防系统、自动驾驶等多个领域的发展。","categories":[{"name":"AI","slug":"AI","permalink":"http://blog.kleon.space/categories/AI/"}],"tags":[{"name":"AI","slug":"AI","permalink":"http://blog.kleon.space/tags/AI/"}]},{"title":"博客事记","slug":"hello","date":"2018-11-20T00:25:02.293Z","updated":"2018-12-13T01:56:21.686Z","comments":true,"path":"2018/11/hello/","link":"","permalink":"http://blog.kleon.space/2018/11/hello/","excerpt":"","text":"2018-11-20 博客上线","categories":[],"tags":[]}]}