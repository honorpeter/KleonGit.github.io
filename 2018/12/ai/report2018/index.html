<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">

  <!-- PACE Progress Bar START -->
  
    <script src="/lib/pace/pace.min.js"></script>
    <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  
  

  <!-- PACE Progress Bar START -->

  
  <title>人工智能路线图 | KLEON</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="AI,IT">
  
  
  
  
  <meta name="description" content="关于深度学习领域相关的算法、系统，还有应用方面的东西。  人工智能这个话题似乎有点儿大。深度学习现在是人工智能领域最重要的一个工具，所以我也趁热学习了一波，把一些我认为有意思的，可能有点用的东西总结在这里。">
<meta name="keywords" content="AI">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能路线图">
<meta property="og:url" content="http://blog.kleon.space/2018/12/ai/report2018/index.html">
<meta property="og:site_name" content="KLEON">
<meta property="og:description" content="关于深度学习领域相关的算法、系统，还有应用方面的东西。  人工智能这个话题似乎有点儿大。深度学习现在是人工智能领域最重要的一个工具，所以我也趁热学习了一波，把一些我认为有意思的，可能有点用的东西总结在这里。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://cdn-images-1.medium.com/max/800/0*We8Aye1G6wLXOCqu.jpg">
<meta property="og:updated_time" content="2018-12-24T14:33:35.504Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="人工智能路线图">
<meta name="twitter:description" content="关于深度学习领域相关的算法、系统，还有应用方面的东西。  人工智能这个话题似乎有点儿大。深度学习现在是人工智能领域最重要的一个工具，所以我也趁热学习了一波，把一些我认为有意思的，可能有点用的东西总结在这里。">
<meta name="twitter:image" content="https://cdn-images-1.medium.com/max/800/0*We8Aye1G6wLXOCqu.jpg">
  
    <link rel="alternate" href="/atom.xml" title="KLEON" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="https://cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  <link rel="stylesheet" href="/css/style.css">

  <script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="/css/hiero.css">
  <link rel="stylesheet" href="/css/glyphs.css">
  

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/css/my.css">
  <!-- Google Adsense -->
  
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-0123456789ABCDEF",
          enable_page_level_ads: true
      });
  </script>
  
</head>
</html>
<script>
var themeMenus = {};

  themeMenus["/"] = "Home"; 

  themeMenus["/archives"] = "Archives"; 

  themeMenus["/categories"] = "Categories"; 

  themeMenus["/tags"] = "Tags"; 

  themeMenus["/about"] = "About"; 

</script>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  <header id="allheader" class="site-header" role="banner">
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" title="KLEON" rel="home"> KLEON </a>
            
          </h1>

          
            <div class="site-description">Think About The Big Map</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>
            <div class="clearfix sf-menu">

              <ul id="main-nav" class="nmenu sf-js-enabled">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">Home</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">Archives</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">Categories</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">Tags</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">About</a> </li>
                    
              </ul>
            </div>
          </nav>


      </div>
  </div>
</header>


  <div id="originBgDiv" style="background: #fff; width: 100%;">

      <div style="max-height:600px; overflow: hidden;  display: flex; display: -webkit-flex; align-items: center;">
        <img id="originBg" width="100%" alt="" src="">
      </div>

  </div>

  <script>
  function setAboutIMG(){
      var imgUrls = "css/images/pose.jpg,https://source.unsplash.com/collection/954550/1920x1080".split(",");
      var random = Math.floor((Math.random() * imgUrls.length ));
      if (imgUrls[random].startsWith('http') || imgUrls[random].indexOf('://') >= 0) {
        document.getElementById("originBg").src=imgUrls[random];
      } else {
        document.getElementById("originBg").src='/' + imgUrls[random];
      }
  }
  bgDiv=document.getElementById("originBgDiv");
  if(location.pathname.match('about')){
    setAboutIMG();
    bgDiv.style.display='block';
  }else{
    bgDiv.style.display='none';
  }
  </script>



  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-ai/report2018" style="width: 66%; float:left;" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
<div class="article-gallery">
  <div class="article-gallery-photos">
    
      <a class="article-gallery-img fancybox" href="https://cdn-images-1.medium.com/max/800/0*We8Aye1G6wLXOCqu.jpg" rel="gallery_cjq31ron0000ekg0x1olaavx8">
        <img src="https://cdn-images-1.medium.com/max/800/0*We8Aye1G6wLXOCqu.jpg" itemprop="image">
      </a>
    
  </div>
</div>

    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      人工智能路线图
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	Posted on <a href="/2018/12/ai/report2018/" class="article-date">
	  <time datetime="2018-12-10T11:00:00.000Z" itemprop="datePublished">December 10, 2018</time>
	</a>

      
	<span id="busuanzi_container_page_pv">
	  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
	</span>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>关于深度学习领域相关的算法、系统，还有应用方面的东西。</p>
</blockquote>
<p>人工智能这个话题似乎有点儿大。深度学习现在是人工智能领域最重要的一个工具，所以我也趁热学习了一波，把一些我认为有意思的，可能有点用的东西总结在这里。</p>
<a id="more"></a>
<!-- ![自动驾驶的图像分割](https://cdn-images-1.medium.com/max/800/0*We8Aye1G6wLXOCqu.jpg) -->
<p>深度学习的核心肯定是算法模型。如果希望模型预测的更准确，模型的计算速度更快，模型能够在移动设备上运行，就需要对模型的结构做调整，对模型的训练做改进。这就属于算法的科研阶段，只要想出更好的模型结构，能够调出比较理想的参数，在一个公开数据集上获得比较理想的结果，那就可以发论文了，至于论文的影响力，那要看你取得的效果，还有你模型对后来人的启发。</p>
<p>模型的训练和部署需要计算框架的支撑。现有的计算框架基本上都是开源的，它们可以基于CPU，这样的好处就是可以支持任何模型，但是这样效率太低，计算速度太慢，尤其是在做训练的时候，当模型的规模越来越大，我可能需要，几天，几周，甚至几个月才能训好，这个是不能接受的。不过好在英伟达比较厉害，显卡的性能在这几年有了突飞猛进的增长，这才有了今天深度学习的蓬勃发展。</p>
<p>用显卡做训练是毋庸置疑的，但是在做预测的时候功耗很高，所以当需要大规模部署的时候，或者说要放在移动设备上的时候，就需要专用芯片了，性能高功耗低，但是开发周期很长，一旦流片就不能改了，而且开发成本很高，如果卖不出多少货，那就亏了。FPGA就是一个折中的方案，它就是可以改变自己逻辑的一个专用芯片，所以可以在上面实现神经网络的逻辑，但是这样的代价就是它的运行速度和功耗都比专用芯片第一个档次，但是它的开发周期短，可能是专用芯片的1/10，所以如果算法变动很快，那么就需要用更快的开发速度去适应这些算法。</p>
<p>对于一个深度学习的计算框架来说，仅仅有芯片是远远不够的，还需要和芯片配套的软件设施，包括模型的解析，计算图的优化，芯片指令的编译和设备的驱动。广义的来说，CPU和GPU也是计算框架中可用的一种芯片，只不过现在的框架可以通过调用面向CPU和GPU优化的线性代数库，支持大部分的算子。英伟达就需要大量的软件开发人员，优化软件，发挥芯片的性能。</p>
<p>当算法的模型稳定下来之后，当计算框架的易用性和性能提升上来之后，那么基于现有深度学习模型的应用才能大规模的铺开。不像早期的时候，应用多半是偏娱乐性质的，现在人工智能的应用已经产业化，并且规模化了。新一代人工智能开放创新平台，包括百度的自动驾驶，阿里云的城市大脑，腾讯的医疗影像，科大讯飞的智能语音，商汤的智能视觉。而且我们也能实实在在地感受到，人工智能对于我们生活的影响力开始逐渐增大了。安防，交通，医疗，工业，教育，这一次不仅仅是人工智能引起的各个产业的变革，更是借助人工智能的这一波红利，去完成我们之前没有做的传统行业的数字化以及互联网化的工作。</p>
<!-- 本文将从多个角度分别展示人工智能的发展现状。深度学习的核心是算法模型，更高的质量，更快的速度都离不开模型的创新与调参。同时训练与执行需要一套高效的系统，主要包括前端框架与后端设备。前端框架搭建与优化模型，后端设备实际运行计算。深度学习系统的开源化使得模型的训练与部署都相当容易，因此基于深度学习的应用也层出不穷，商业与技术结合碰撞出火花和泡沫。
小伙伴们，你想变强吗？不想，呵呵！本文将从多个角度分别展示人工智能的发展现状，深度学习的核心是模型算法，更高的质量，更快的速度，都离不开模型的创新与挑战，同时训练与执行需要一套高效的系统，主要包括前端框架与后端设备，前端框架搭建与优化模型，后端设备实际运行模型，深度学习的开源化，使得模型的训练与部署都相当容易，因此基于深度学习的应用也层出不穷，商业与技术结合碰撞出火花，当然还有泡沫， -->
<!-- <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=640 height=86 src="//music.163.com/outchain/player?type=2&id=357312&auto=1&height=66"></iframe> -->
<h1 id="模型">模型</h1>
<p>深度学习模型的最基本的思想就是复合多层非线性函数的来拟合任何函数。深度学习的深度就体现在复合函数的层次的深度。深度学习从神经的连接方式中获得启发，其中最早的就是深度神经网络（DNN，Deep Neural Network），又称全连接网络（FCNN，Fully Connected Neural Network），又称。随后，卷积神经网络（CNN，Convolutional Neural Network）和递归神经网络（RNN，Recurrent Neural Network）带来了计算机视觉、语音，以及自然语言处理领域的重大突破。ResNet结构可以避免梯度消失，增加网络的深度。</p>
<h2 id="计算机视觉">计算机视觉</h2>
<p>计算机视觉领域的五大技术包括：</p>
<ul>
<li>图像分类</li>
<li>对象检测</li>
<li>目标跟踪</li>
<li>语义分割</li>
<li>实例分割</li>
</ul>
<h3 id="图像分类">图像分类</h3>
<p>传统的图像分类方法建立图像识别模型，一般包括底层特征学习，特征编码，空间约束分类器设计，模型融合等阶段。而CNN模型（AlexNet）的效果大幅超越了传统方法，随着模型的结构改进，错误率也越来越低，识别能力甚至超过了人眼。</p>
<figure>
<img src="https://pic3.zhimg.com/80/e63b5f227f76850b02c241d75a3c50ba_hd.png" alt="CNN发展2016"><figcaption>CNN发展2016</figcaption>
</figure>
<p>CNN包括卷积层，池化层，全连接层，使用Sigmoid、Tanh、ReLu等作为激活函数，可以采用Dropout防止过拟合，使用Batch Normalization（BN）对特征做归一化，加速收敛过程。CNN引入了信号处理领域的概念卷积，使用权值共享与局部感受野大幅降低了参数规模，使得计算得以执行。</p>
<figure>
<img src="https://cdn-images-1.medium.com/max/1600/1*LNi7r7NKB5av_RGqxxhwGQ.png" alt="CNN架构"><figcaption>CNN架构</figcaption>
</figure>
<p>图像分类作为计算机视觉的第一步，负责感知图片的结构与特征，通常用作前置骨干网络。主要的模型包括：</p>
<ul>
<li>VGG</li>
<li>GoogleNet</li>
<li>ResNet</li>
<li>MobileNet</li>
</ul>
<figure>
<img src="https://slideplayer.com/slide/12039897/69/images/42/ResNet%3A+going+real+deep.jpg" alt="常见CNN网络"><figcaption>常见CNN网络</figcaption>
</figure>
<h4 id="lenet"><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">LeNet</a></h4>
<p>LeNet可以说是CNN的开端，包含了CNN的所有基础组件：卷积层，池化层，全连接层，使用Sigmoid作为激活函数。</p>
<figure>
<img src="https://pic1.zhimg.com/80/6f38ab4ba2122f6a901f5b87ee5878fc_hd.jpg" alt="LeNet网络结构"><figcaption>LeNet网络结构</figcaption>
</figure>
<h4 id="alexnet"><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">AlexNet</a></h4>
<figure>
<img src="http://www.cs.cornell.edu/courses/cs4670/2016sp/projects/pa5/alexnet.png" alt="AlexNet结构"><figcaption>AlexNet结构</figcaption>
</figure>
<p>AlexNet可以算作CNN的突破，取决于：</p>
<ul>
<li>非线性激活函数：ReLU</li>
<li>防止过拟合：Dropout，Data augmentation</li>
<li>大数据量训练：百万级ImageNet图像数据</li>
<li>异构计算：GPU</li>
<li>LRN(Local Responce Normalization)归一化</li>
</ul>
<h4 id="vgg"><a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">VGG</a></h4>
<p>VGG相较于AlexNet，采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。但VGG使用3层全连接层，参数规模较大，但收益不高。</p>
<figure>
<img src="http://3.bp.blogspot.com/-0-i94WQO1dE/VTUiGLxiEtI/AAAAAAAAAsI/tamhfG_uwb4/s1600/%E6%93%B7%E5%8F%96.PNG" alt="VGG结构，VGG16（D），VGG19（E）"><figcaption>VGG结构，VGG16（D），VGG19（E）</figcaption>
</figure>
<h4 id="googlenet"><a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">GoogLeNet</a></h4>
<h5 id="inception-v1">Inception V1</h5>
<p>GoogLeNet参数较少（AlexNet参数个数是GoogleNet的12倍，VGGNet参数又是AlexNet的3倍），性能较高。GoogLeNet经历了Inception V1到V4的发展。Inception V1通过设计一个稀疏网络结构，但是能够产生稠密的数据，既能增加神经网络表现，又能保证计算资源的使用效率。通过1x1的卷积核，减少计算量</p>
<p><img src="http://simtalk.cn/img/GoogLeNet/Inception3.jpg" alt="Inception V1基本思想"> <img src="http://simtalk.cn/img/GoogLeNet/Inception.PNG" alt="Inception V1 1x1卷积"></p>
<figure>
<img src="http://simtalk.cn/img/GoogLeNet/net.PNG" alt="GoogLeNet结构"><figcaption>GoogLeNet结构</figcaption>
</figure>
<h5 id="inception-v2"><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">Inception V2</a></h5>
<p>Inception V2论文主要提出了Batch Normalization，使得训练深度神经网络成为了可能。 在传统机器学习中，对图像提取特征之前，都会对图像做白化操作，即对输入数据变换成0均值、单位方差的正态分布。 卷积神经网络的输入就是图像，白化操作可以加快收敛，对于深度网络，每个隐层的输出都是下一个隐层的输入，即每个隐层的输入都可以做白化操作。 BN可用于加速网络训练，防止梯度消失。如果激活函数是sigmoid，对于每个神经元，可以把逐渐向非线性映射的两端饱和区靠拢的输入分布，强行拉回到0均值单位方差的标准正态分布，即激活函数的兴奋区，在sigmoid兴奋区梯度大，即加速网络训练，还防止了梯度消失。Inception V2的思想同VGG，5x5卷积用3x3卷积代替。</p>
<h5 id="inception-v3"><a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" rel="noopener">Inception V3</a></h5>
<p>Inception V3引入了：</p>
<ul>
<li>卷积分解（Factorizing Convolutions），用多个连续小尺寸卷积代替大尺寸卷积。</li>
<li>非对称卷积，nxn的卷积分解成1xn和nx1卷积的串联，减少计算量，提高深度，</li>
<li>降低特征图大小，用并行Conv与Pool代替串联Inception与Pool。</li>
<li>使用Label Smoothing来对网络输出进行正则化。</li>
</ul>
<p><img src="https://static.oschina.net/uploads/space/2018/0317/141713_bGpL_876354.png" alt="卷积分解"> <img src="https://static.oschina.net/uploads/space/2018/0317/141734_OEPA_876354.png" alt="并行Conv与Pool"></p>
<figure>
<img src="https://static.oschina.net/uploads/space/2018/0317/141739_flcW_876354.png" alt="Inception V3改进的GoogLeNet"><figcaption>Inception V3改进的GoogLeNet</figcaption>
</figure>
<p>上表中的Figure 5指没有进化的Inception，Figure 6是指小卷积版的Inception（用3x3卷积核代替5x5卷积核），Figure 7是指不对称版的Inception（用1xn、nx1卷积核代替nxn卷积核）。</p>
<h5 id="inception-v4"><a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" rel="noopener">Inception V4</a></h5>
<p>Inception V4研究了Inception模块与残差连接的结合。ResNet结构大大地加深了网络深度，还极大地提升了训练速度，同时性能也有提升。</p>
<figure>
<img src="https://static.oschina.net/uploads/space/2018/0317/141810_oD01_876354.png" alt="Inception-ResNet"><figcaption>Inception-ResNet</figcaption>
</figure>
<h4 id="resnet"><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">ResNet</a></h4>
<p>ResNet基于一个假设：直接映射是难以学习的，不再学习从 x 到 H(x) 的基本映射关系，而是学习这两者之间的差异，也就是<strong>残差</strong>（residual）。然后，为了计算 H(x)，我们只需要将这个残差加到输入上即可。</p>
<figure>
<img src="https://ask.qcloudimg.com/http-save/yehe-781483/euea0e2zzl.jpeg?imageView2/2/w/1620" alt="ResNet基本结构"><figcaption>ResNet基本结构</figcaption>
</figure>
<figure>
<img src="https://upload-images.jianshu.io/upload_images/6011252-4e46fd38e757c320?imageMogr2/auto-orient/strip%7CimageView2/2/w/553/format/webp" alt="ResNet结构示意图"><figcaption>ResNet结构示意图</figcaption>
</figure>
<h4 id="mobilenet"><a href="https://arxiv.org/pdf/1704.04861.pdf" target="_blank" rel="noopener">MobileNet</a></h4>
<p>基本假设是：跨通道的相关性和空间相关性是完全可分离的，最好不要联合映射它们。同时期的<a href="https://arxiv.org/pdf/1610.02357.pdf" target="_blank" rel="noopener">Xception</a>也有类似发现。 引入了深度可分离卷积（Depthwise Separable Convolution）。Depthwise指不跨通道的卷积，也就是说Feature Map的每个通道有一个独立的卷积核，并且这个卷积核作用且仅作用在这个通道之上。 相较于传统3D卷积，Depthwise卷积如下：</p>
<figure>
<img src="https://img-blog.csdn.net/20171223141505838" alt="3D卷积与Depthwise卷积对比"><figcaption>3D卷积与Depthwise卷积对比</figcaption>
</figure>
<p>Depthwise结合1x1的卷积方式更高效，降低了计算量，并且1x1卷积不需要im2col的数据排布，适合移动端。</p>
<figure>
<img src="https://img-blog.csdn.net/20171223141525891" alt="MobileNet结构"><figcaption>MobileNet结构</figcaption>
</figure>
<p><a href="https://arxiv.org/pdf/1801.04381.pdf" target="_blank" rel="noopener">MobileNet V2</a>是MobileNet的改进版本。引入了Linear bottleneck Inverted Residual Block结构。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-0e04a172a66e8f0f1db2bb31623987a1_hd.jpg" alt="Linear bottleneck Inverted Residual Block结构"><figcaption>Linear bottleneck Inverted Residual Block结构</figcaption>
</figure>
<h3 id="对象检测">对象检测</h3>
<p>获得了图像的分类，对象检测用来获取对象在图像中的位置，呈现结果为便签+打框。主要分为两大类：</p>
<ul>
<li>候选区域与分类
<ul>
<li>RCNN</li>
<li>SPP-Net</li>
<li>Fast RCNN</li>
<li>Faster RCNN</li>
<li>R-FCN</li>
</ul></li>
<li>端到端
<ul>
<li>YOLO</li>
<li>SSD</li>
</ul></li>
</ul>
<h4 id="r-cnn">R-CNN</h4>
<h4 id="fast-r-cnn">Fast R-CNN</h4>
<h4 id="faster-r-cnn">Faster R-CNN</h4>
<h4 id="yolo">YOLO</h4>
<h4 id="ssd">SSD</h4>
<h4 id="retinanet"><a href="https://arxiv.org/pdf/1708.02002.pdf" target="_blank" rel="noopener">RetinaNet</a></h4>
<h3 id="目标跟踪">目标跟踪</h3>
<p>目标跟踪用于动态识别目标的运动轨迹，比如人脸，车辆，行人。</p>
<p><a href="https://pic2.zhimg.com/v2-e77c8fc7428a0228e5f6b8d54dad4ca1_b.gif" target="_blank" rel="noopener">非常鲁棒的人脸跟踪</a></p>
<p>目标跟踪算法包括：</p>
<ul>
<li>SiameseFC tracker：end2end离线训练tracker</li>
<li>相关滤波</li>
<li>CFNet</li>
<li>MDNet</li>
</ul>
<h3 id="语义分割">语义分割</h3>
<h4 id="fcn">FCN</h4>
<h4 id="segnet">SegNet</h4>
<h4 id="unet">UNet</h4>
<h4 id="enet">ENet</h4>
<h4 id="psp-net">PSP Net</h4>
<h3 id="实例分割">实例分割</h3>
<h4 id="deep-mask">Deep Mask</h4>
<h4 id="multi-task-network-cascadesmnc">Multi-task Network Cascades(MNC)</h4>
<h4 id="fcis">FCIS</h4>
<h4 id="mask-rcnn">Mask RCNN</h4>
<h2 id="语音">语音</h2>
<h2 id="自然语言处理">自然语言处理</h2>
<!-- <iframe src="//player.bilibili.com/player.html?aid=37942085&cid=66699398&page=1" scrolling="no" border="0" width="640" height="359" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
 -->
<h1 id="系统">系统</h1>
<p>深度学习系统正在不断发展与完善之中。利用深度学习框架，就可以可以搭建神经网络，并在CPU与GPU上执行。 主流的计算框架包括：</p>
<ul>
<li>Google家的Tensorflow，背靠TPU</li>
<li>Facebook家的PyTorch</li>
<li>UCB家的Caffe</li>
</ul>
<!-- <iframe width="640" height="355" src="https://www.youtube.com/embed/-O5kNPlUV7w?controls=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
<p>这些框架的主要目标平台是GPU，但GPU功耗较高，端到端延迟较大，几乎统治了训练领域。在预测领域，专用芯片可以获得比GPU更高的效率，并且可以根据场景的性能要求与功耗限制定制芯片。</p>
<p>因此适配不同框架到不同的后端设备成了必要的需求。微软、脸书、亚马逊共同推出的ONNX（Open Neural Network Exchange）试图通过统一的Runtime沟通不同的前端框架；NNVM携带自己的TVM试图搭建前端到设备端的编译路径；而Tensorflow自成一体，使用XLA统一中间表示，并适配不同后端设备的优化pass。</p>
<h2 id="框架">框架</h2>
<!-- ![Summer](/images/01.jpg) -->
<p>深度学习训练与部署的框架百花齐放，以Tensorflow为首，PyTorch，Caffe等紧随其后。各家平台构建网络时特点不同，并不同程度地支持分布式训练。由于社区的开源工作，单机搭建深度学习平台已经相当容易，然而受限于计算资源，难以训练较大规模的模型。对深度学习的训练与部署平台的需求也与日俱增。 除此之外，框架对于底层计算平台的可拓展能力也被看重，Tensorflow的XLA，NNVM的TVM都利用统一的IR与优化pass适配不同的底层硬件。</p>
<h3 id="tensorflow">Tensorflow</h3>
<h3 id="pytorch">PyTorch</h3>
<h3 id="caffe">Caffe</h3>
<h2 id="设备">设备</h2>
<p>深度学习模型训练（Training）与预测（Inference）在CPU上表现欠佳，因而发展出了多种类型的异构计算系统用于加速模型的训练与预测。以GPU为首，NVIDIA推出cuDNN库，作为各种框架的底层平台，已经得到了大规模的应用。除此之外，各类专用芯片也迅速进入异构计算系统中。以FPGA为平台，可以较快适应模型的算法创新，虽然可以获得较高的加速比，但计算效率并不高。ASIC芯片中，以Google的TPU最为出名，同时支持训练与预测。</p>
<h3 id="gpu">GPU</h3>
<h3 id="fpga">FPGA</h3>
<h3 id="asic">ASIC</h3>
<h2 id="编译">编译</h2>
<h3 id="section"></h3>
<h1 id="应用">应用</h1>
<p>深度学习目前在图像识别领域最为成熟，各类模型与系统最为丰富。基于图像识别领域的目标检测，语义分割等，支撑了工业检测、安防系统、自动驾驶等多个领域的发展。</p>
<h2 id="自动驾驶">自动驾驶</h2>
<h2 id="医疗">医疗</h2>
<h2 id="语音-1">语音</h2>
<h2 id="城市大脑">城市大脑</h2>
<h2 id="视觉">视觉</h2>

      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/AI/">AI</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li></ul>

      
            
      
        
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'kleon';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>


      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/11/hello/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">博客事记</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article" style="overflow-y: scroll; max-width: 28%;">
    <strong class="toc-title">Contents</strong>
    
      <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#模型"><span class="nav-number">1.</span> <span class="nav-text">模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#计算机视觉"><span class="nav-number">1.1.</span> <span class="nav-text">计算机视觉</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#图像分类"><span class="nav-number">1.1.1.</span> <span class="nav-text">图像分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#lenet"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">LeNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#alexnet"><span class="nav-number">1.1.1.2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#vgg"><span class="nav-number">1.1.1.3.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#googlenet"><span class="nav-number">1.1.1.4.</span> <span class="nav-text">GoogLeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#inception-v1"><span class="nav-number">1.1.1.4.1.</span> <span class="nav-text">Inception V1</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#inception-v2"><span class="nav-number">1.1.1.4.2.</span> <span class="nav-text">Inception V2</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#inception-v3"><span class="nav-number">1.1.1.4.3.</span> <span class="nav-text">Inception V3</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#inception-v4"><span class="nav-number">1.1.1.4.4.</span> <span class="nav-text">Inception V4</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#resnet"><span class="nav-number">1.1.1.5.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mobilenet"><span class="nav-number">1.1.1.6.</span> <span class="nav-text">MobileNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对象检测"><span class="nav-number">1.1.2.</span> <span class="nav-text">对象检测</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#r-cnn"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fast-r-cnn"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">Fast R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#faster-r-cnn"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">Faster R-CNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#yolo"><span class="nav-number">1.1.2.4.</span> <span class="nav-text">YOLO</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ssd"><span class="nav-number">1.1.2.5.</span> <span class="nav-text">SSD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#retinanet"><span class="nav-number">1.1.2.6.</span> <span class="nav-text">RetinaNet</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#目标跟踪"><span class="nav-number">1.1.3.</span> <span class="nav-text">目标跟踪</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#语义分割"><span class="nav-number">1.1.4.</span> <span class="nav-text">语义分割</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#fcn"><span class="nav-number">1.1.4.1.</span> <span class="nav-text">FCN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#segnet"><span class="nav-number">1.1.4.2.</span> <span class="nav-text">SegNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#unet"><span class="nav-number">1.1.4.3.</span> <span class="nav-text">UNet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#enet"><span class="nav-number">1.1.4.4.</span> <span class="nav-text">ENet</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#psp-net"><span class="nav-number">1.1.4.5.</span> <span class="nav-text">PSP Net</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实例分割"><span class="nav-number">1.1.5.</span> <span class="nav-text">实例分割</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#deep-mask"><span class="nav-number">1.1.5.1.</span> <span class="nav-text">Deep Mask</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#multi-task-network-cascadesmnc"><span class="nav-number">1.1.5.2.</span> <span class="nav-text">Multi-task Network Cascades(MNC)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#fcis"><span class="nav-number">1.1.5.3.</span> <span class="nav-text">FCIS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mask-rcnn"><span class="nav-number">1.1.5.4.</span> <span class="nav-text">Mask RCNN</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#语音"><span class="nav-number">1.2.</span> <span class="nav-text">语音</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自然语言处理"><span class="nav-number">1.3.</span> <span class="nav-text">自然语言处理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#系统"><span class="nav-number">2.</span> <span class="nav-text">系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#框架"><span class="nav-number">2.1.</span> <span class="nav-text">框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#tensorflow"><span class="nav-number">2.1.1.</span> <span class="nav-text">Tensorflow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pytorch"><span class="nav-number">2.1.2.</span> <span class="nav-text">PyTorch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#caffe"><span class="nav-number">2.1.3.</span> <span class="nav-text">Caffe</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#设备"><span class="nav-number">2.2.</span> <span class="nav-text">设备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#gpu"><span class="nav-number">2.2.1.</span> <span class="nav-text">GPU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#fpga"><span class="nav-number">2.2.2.</span> <span class="nav-text">FPGA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#asic"><span class="nav-number">2.2.3.</span> <span class="nav-text">ASIC</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编译"><span class="nav-number">2.3.</span> <span class="nav-text">编译</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#section"><span class="nav-number">2.3.1.</span> <span class="nav-text"></span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#应用"><span class="nav-number">3.</span> <span class="nav-text">应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#自动驾驶"><span class="nav-number">3.1.</span> <span class="nav-text">自动驾驶</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#医疗"><span class="nav-number">3.2.</span> <span class="nav-text">医疗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#语音-1"><span class="nav-number">3.3.</span> <span class="nav-text">语音</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#城市大脑"><span class="nav-number">3.4.</span> <span class="nav-text">城市大脑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#视觉"><span class="nav-number">3.5.</span> <span class="nav-text">视觉</span></a></li></ol></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2018-2018 KLEON All Rights Reserved.
      </div>
      <div class="site-count">
          
            <span id="busuanzi_container_site_uv">
              本站访客数<span id="busuanzi_value_site_uv"></span>人次  
              本站总访问量<span id="busuanzi_value_site_pv"></span>次
            </span>
          
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var contentdiv = document.getElementById("content");

    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
</script>

<!-- Custome JS -->
<script src="/js/my.js"></script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.js"></script>


<script src="/js/scripts.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>







  <div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="https://dnqof95d40fo6.cloudfront.net/atw7f8.js">
	</script>






  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>
</body>
</html>
