<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[人工智能路线图]]></title>
    <url>%2F2018%2F12%2Fai%2Freport2018%2F</url>
    <content type="text"><![CDATA[这是一篇测试文档。 人工智能技术伴随数字化与联网化的趋势不断发展。人工智能是一个技术大类，包含了机器学习、专家系统、知识工程等多个分支。机器学习，尤其是深度学习近年来发展迅速，在许多方面有了较大的突破，提升了如搜索引擎、内容推荐、图像识别、语音识别、语言翻译等应用的质量与效率。 本文将从多个角度分别展示人工智能的发展现状。 模型 对于深度学习算法来说，神经网络的模型是最为关键的。模型的种类与规模成千上万，但都基于三种基本的网络层结构：DNN、CNN、RNN。在这三种网络层结构之上又引入了多层结构，如Resnet，Inception等，用于避免梯度消失和降低计算量等。在基本的网络结构之上，构建了面向不同应用领域的模型，如GAN，RL，GNN等。 框架 深度学习训练与部署的框架百花齐放，以Tensorflow为首，PyTorch，Caffe等紧随其后。各家平台构建网络时特点不同，并不同程度地支持分布式训练。由于社区的开源工作，单机搭建深度学习平台已经相当容易，然而受限于计算资源，难以训练较大规模的模型。对深度学习的训练与部署平台的需求也与日俱增。 除此之外，框架对于底层计算平台的可拓展能力也被看重，Tensorflow的XLA，NNVM的TVM都利用统一的IR与优化pass适配不同的底层硬件。 系统 深度学习模型训练（Training）与预测（Inference）在CPU上表现欠佳，因而发展出了多种类型的异构计算系统用于加速模型的训练与预测。以GPU为首，NVIDIA推出cuDNN库，作为各种框架的底层平台，已经得到了大规模的应用。除此之外，各类专用芯片也迅速进入异构计算系统中。以FPGA为平台，可以较快适应模型的算法创新，虽然可以获得较高的加速比，但计算效率并不高。ASIC芯片中，以Google的TPU最为出名，同时支持训练与预测。 应用 深度学习目前在图像识别领域最为成熟，各类模型与系统最为丰富。基于图像识别领域的目标检测，语义分割等，支撑了工业检测、安防系统、自动驾驶等多个领域的发展。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客事记]]></title>
    <url>%2F2018%2F11%2Fhello%2F</url>
    <content type="text"><![CDATA[2018-11-20 博客上线]]></content>
  </entry>
</search>
